{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a9b0720-61f6-4a8a-ac68-d0c77e25fe86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T15:29:03.057392Z",
     "start_time": "2025-12-03T15:29:03.055724Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "import requests\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "# -------------------- CONFIG --------------------\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:120.0) Gecko/20100101 Firefox/120.0\",\n",
    "    \"Access-Control-Allow-Origin\": \"*\"\n",
    "}\n",
    "\n",
    "input_csv = \"data/annonces_link.csv\"    \n",
    "output_csv = \"data/results.csv\"          \n",
    "\n",
    "# -------------------- UTILITIES --------------------\n",
    "def remove_whitespace(s: str, keep_spaces: bool = True) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = re.sub(r\"[^\\S ]+\", \" \", s)\n",
    "    s = re.sub(r\" +\", \" \", s)\n",
    "    s = re.sub(r\"\\\\\", \"\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def get_specific_element(regex: str, text: str):\n",
    "    if not text:\n",
    "        return None\n",
    "    m = re.search(regex, text)\n",
    "    return m.group(0) if m else None\n",
    "\n",
    "def safe_text(element, keep_spaces=False):\n",
    "    if not element:\n",
    "        return \"\"\n",
    "    try:\n",
    "        e = element.text\n",
    "    except AttributeError:\n",
    "        e = element\n",
    "    return remove_whitespace(e, keep_spaces)\n",
    "\n",
    "def stringToTimeStamp(date_str:str):\n",
    "    dt = datetime.strptime(date_str, \"%d/%m/%Y %H:%M\")\n",
    "    return int(dt.timestamp())\n",
    "    \n",
    "\n",
    "def safe_find_text(soup, tag, attrs=None, keep_spaces=False):\n",
    "    element = soup.find(tag, attrs=attrs)\n",
    "    return safe_text(element, keep_spaces) if element else \"\"\n",
    "\n",
    "def scrape_annonce(url, htmlContent):\n",
    "    \"\"\"\n",
    "    Scrapes a ParuVendu annonce page:\n",
    "    - Selenium: handles dynamic content & clicks 'Lire plus'\n",
    "    - BeautifulSoup: parses static content\n",
    "    \"\"\"\n",
    "    # ---------- SELENIUM ----------\n",
    "    opt = Options()\n",
    "    opt.add_argument(\"start-maximized\")\n",
    "    opt.add_argument(\"--lang=en-US\")\n",
    "\n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(ChromeDriverManager().install()),\n",
    "        options=opt\n",
    "    )\n",
    "\n",
    "    driver.get(url)\n",
    "    sleep(2)\n",
    "\n",
    "    # Accept cookies\n",
    "    try:\n",
    "        btn = driver.find_element(By.XPATH, \"//button[text()='Accepter']\")\n",
    "        driver.execute_script(\"arguments[0].click();\", btn)\n",
    "        sleep(1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Cliquer sur  \"Lire plus\" si ca exite \n",
    "    try:\n",
    "        read_more = driver.find_element(By.ID, \"linkAnnonceTrunc\")\n",
    "        driver.execute_script(\"arguments[0].click();\", read_more)\n",
    "        sleep(1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Extraire la description\n",
    "    try:\n",
    "        element = driver.find_element(By.XPATH, \"//div[@class='im12_txt_ann im12_txt_ann_auto']\")\n",
    "        description = element.text\n",
    "    except:\n",
    "        description = \"\"\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # ---------- BEAUTIFULSOUP ----------\n",
    "    data = {}\n",
    "    if htmlContent:\n",
    "        soup = BeautifulSoup(htmlContent, 'html.parser')\n",
    "        data[\"title\"] = safe_find_text(soup, \"span\", {\"id\": \"detail_h1\"}, True)\n",
    "        data[\"location\"] = safe_find_text(soup, \"span\", {\"id\": \"detail_loc\"})\n",
    "        data[\"descriptionTitle\"] = safe_find_text(soup, \"h2\", {\"class\": \"autodetail-titre sepdetail14-ssbordure\"})\n",
    "        data[\"description\"] = safe_text(description)\n",
    "        data[\"nbp\"] = get_specific_element(r\"\\d+\", safe_find_text(soup, \"li\", {\"class\": \"nbp\"}))\n",
    "        data[\"surf\"] = get_specific_element(r\"\\d+\", safe_find_text(soup, \"li\", {\"class\": \"surf\"}))\n",
    "        data[\"prix\"] = get_specific_element(r\"\\d+(?: \\d+)*\", safe_find_text(soup, \"div\", {\"class\": \"prixactionalerte-box\"}))\n",
    "        data[\"enseigneInfosvendeur\"] = safe_find_text(soup, \"p\", {\"class\": \"enseigne-infosvendeur\"})\n",
    "        # data[\"enseigneInfosvendeur\"] = safe_find_text(soup, \"p\", {\"class\": \"enseigne-infosvendeur\"})\n",
    "\n",
    "        uls = soup.find_all(\"ul\", {\"class\": \"crit-alignbloc\"})\n",
    "        \n",
    "        for idx, ul in enumerate(uls, 1):\n",
    "            datas = {}\n",
    "            li_items = ul.find_all(\"li\")\n",
    "        \n",
    "            for li in li_items:\n",
    "        \n",
    "                strong = li.find(\"strong\")\n",
    "                if strong:  \n",
    "                    # category is inside <strong>\n",
    "                    category = strong.get_text(strip=True)\n",
    "                else:\n",
    "                    # category is plain text before spans\n",
    "                    category = li.get_text(\" \", strip=True).split(\" \")[0]\n",
    "        \n",
    "                values = [span.get_text(strip=True) for span in li.find_all(\"span\")]\n",
    "                datas[category] = values\n",
    "        \n",
    "        data[\"agencement\"] = \",\".join(datas.get(\"Agencement\", []))\n",
    "        data[\"general\"] = \",\".join(datas.get(\"Général\", []))\n",
    "        data[\"annexe\"] = \",\".join(datas.get(\"Annexes\", []))\n",
    "\n",
    "        data[\"dependance\"] = \",\".join(datas.get(\"Dépendance\", []))\n",
    "\n",
    "        # Tranformer la date en timestamp\n",
    "        raw_date = datas.get(\"Mise\", [])\n",
    "        if raw_date:\n",
    "            date_str = raw_date[0].replace(\" à \", \" \")\n",
    "            data[\"publishedAt\"] = stringToTimeStamp(date_str)\n",
    "        else:\n",
    "            data[\"publishedAt\"] = None\n",
    "\n",
    "\n",
    "        data[\"reference\"] =  safe_text(datas.get(\"Réf.\")[0],[])\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a24d32b-f199-46b7-b33c-4b3d44ff957a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T15:29:03.272445Z",
     "start_time": "2025-12-03T15:29:03.073309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trouvé 1338 lignes dans results.csv\n",
      "Trouvé 1 erreurs dans results_errors.csv\n",
      "Total: 1333 liens uniques déjà traités (succès + erreurs).\n",
      "Reprise avec 14387 liens restants à traiter.\n",
      "Traitement: https://www.paruvendu.fr/immobilier/vente/appartement/1265798356A1KIVHAP000  (1339/14926)\n",
      "Traitement: https://www.paruvendu.fr/immobilier/vente/appartement/1286219307A1KIVHAP000  (1340/14926)\n",
      "Traitement: https://www.paruvendu.fr/immobilier/vente/appartement/1284377599A1KIVHAP000  (1341/14926)\n",
      "Traitement: https://www.paruvendu.fr/immobilier/vente/appartement/1286524608A1KIVHAP000  (1342/14926)\n",
      "Traitement: https://www.paruvendu.fr/immobilier/vente/maison/1283970845A1KIVHMN000  (1343/14926)\n",
      "Traitement: https://www.paruvendu.fr/immobilier/prestige/maison/1286328857A1KIVHMN000  (1344/14926)\n",
      "Traitement: https://www.paruvendu.fr/immobilier/vente/appartement/1286259065A1KIVHAP000  (1345/14926)\n",
      "Traitement: https://www.paruvendu.fr/immobilier/vente/appartement/1285652231A1KIVHAP000  (1346/14926)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     68\u001b[39m content = response.text\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m data = scrape_annonce(link, content)\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Sérialiser les données scrapées en JSON pour éviter les problèmes de séparation de colonnes CSV\u001b[39;00m\n\u001b[32m     72\u001b[39m writer.writerow([link, json.dumps(data, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m)])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mscrape_annonce\u001b[39m\u001b[34m(url, htmlContent)\u001b[39m\n\u001b[32m     67\u001b[39m opt.add_argument(\u001b[33m\"\u001b[39m\u001b[33mstart-maximized\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     68\u001b[39m opt.add_argument(\u001b[33m\"\u001b[39m\u001b[33m--lang=en-US\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m driver = webdriver.Chrome(\n\u001b[32m     71\u001b[39m     service=Service(ChromeDriverManager().install()),\n\u001b[32m     72\u001b[39m     options=opt\n\u001b[32m     73\u001b[39m )\n\u001b[32m     75\u001b[39m driver.get(url)\n\u001b[32m     76\u001b[39m sleep(\u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/site-packages/selenium/webdriver/chrome/webdriver.py:45\u001b[39m, in \u001b[36mWebDriver.__init__\u001b[39m\u001b[34m(self, options, service, keep_alive)\u001b[39m\n\u001b[32m     42\u001b[39m service = service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[32m     43\u001b[39m options = options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m     46\u001b[39m     browser_name=DesiredCapabilities.CHROME[\u001b[33m\"\u001b[39m\u001b[33mbrowserName\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     47\u001b[39m     vendor_prefix=\u001b[33m\"\u001b[39m\u001b[33mgoog\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     48\u001b[39m     options=options,\n\u001b[32m     49\u001b[39m     service=service,\n\u001b[32m     50\u001b[39m     keep_alive=keep_alive,\n\u001b[32m     51\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/site-packages/selenium/webdriver/chromium/webdriver.py:66\u001b[39m, in \u001b[36mChromiumDriver.__init__\u001b[39m\u001b[34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[39m\n\u001b[32m     57\u001b[39m executor = ChromiumRemoteConnection(\n\u001b[32m     58\u001b[39m     remote_server_addr=\u001b[38;5;28mself\u001b[39m.service.service_url,\n\u001b[32m     59\u001b[39m     browser_name=browser_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m     62\u001b[39m     ignore_proxy=options._ignore_local_proxy,\n\u001b[32m     63\u001b[39m )\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(command_executor=executor, options=options)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m     68\u001b[39m     \u001b[38;5;28mself\u001b[39m.quit()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/site-packages/selenium/webdriver/remote/webdriver.py:212\u001b[39m, in \u001b[36mWebDriver.__init__\u001b[39m\u001b[34m(self, command_executor, keep_alive, file_detector, options)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28mself\u001b[39m._authenticator_id = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[38;5;28mself\u001b[39m.start_client()\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m \u001b[38;5;28mself\u001b[39m.start_session(capabilities)\n\u001b[32m    214\u001b[39m \u001b[38;5;28mself\u001b[39m._websocket_connection = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m._script = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/site-packages/selenium/webdriver/remote/webdriver.py:299\u001b[39m, in \u001b[36mWebDriver.start_session\u001b[39m\u001b[34m(self, capabilities)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Creates a new session with the desired capabilities.\u001b[39;00m\n\u001b[32m    293\u001b[39m \n\u001b[32m    294\u001b[39m \u001b[33;03m:Args:\u001b[39;00m\n\u001b[32m    295\u001b[39m \u001b[33;03m - capabilities - a capabilities dict to start the session with.\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    298\u001b[39m caps = _create_caps(capabilities)\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m response = \u001b[38;5;28mself\u001b[39m.execute(Command.NEW_SESSION, caps)[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    300\u001b[39m \u001b[38;5;28mself\u001b[39m.session_id = response.get(\u001b[33m\"\u001b[39m\u001b[33msessionId\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    301\u001b[39m \u001b[38;5;28mself\u001b[39m.caps = response.get(\u001b[33m\"\u001b[39m\u001b[33mcapabilities\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/site-packages/selenium/webdriver/remote/webdriver.py:352\u001b[39m, in \u001b[36mWebDriver.execute\u001b[39m\u001b[34m(self, driver_command, params)\u001b[39m\n\u001b[32m    349\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msessionId\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m    350\u001b[39m         params[\u001b[33m\"\u001b[39m\u001b[33msessionId\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.session_id\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m response = \u001b[38;5;28mself\u001b[39m.command_executor.execute(driver_command, params)\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[32m    354\u001b[39m     \u001b[38;5;28mself\u001b[39m.error_handler.check_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/site-packages/selenium/webdriver/remote/remote_connection.py:306\u001b[39m, in \u001b[36mRemoteConnection.execute\u001b[39m\u001b[34m(self, command, params)\u001b[39m\n\u001b[32m    304\u001b[39m trimmed = \u001b[38;5;28mself\u001b[39m._trim_large_entries(params)\n\u001b[32m    305\u001b[39m LOGGER.debug(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, command_info[\u001b[32m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(command_info[\u001b[32m0\u001b[39m], url, body=data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/site-packages/selenium/webdriver/remote/remote_connection.py:326\u001b[39m, in \u001b[36mRemoteConnection._request\u001b[39m\u001b[34m(self, method, url, body)\u001b[39m\n\u001b[32m    323\u001b[39m     body = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keep_alive:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._conn.request(method, url, body=body, headers=headers)\n\u001b[32m    327\u001b[39m     statuscode = response.status\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/site-packages/urllib3/_request_methods.py:143\u001b[39m, in \u001b[36mRequestMethods.request\u001b[39m\u001b[34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request_encode_url(\n\u001b[32m    136\u001b[39m         method,\n\u001b[32m    137\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m         **urlopen_kw,\n\u001b[32m    141\u001b[39m     )\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request_encode_body(\n\u001b[32m    144\u001b[39m         method, url, fields=fields, headers=headers, **urlopen_kw\n\u001b[32m    145\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/site-packages/urllib3/_request_methods.py:278\u001b[39m, in \u001b[36mRequestMethods.request_encode_body\u001b[39m\u001b[34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[39m\n\u001b[32m    274\u001b[39m     extra_kw[\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m].setdefault(\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m, content_type)\n\u001b[32m    276\u001b[39m extra_kw.update(urlopen_kw)\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.urlopen(method, url, **extra_kw)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/site-packages/urllib3/poolmanager.py:459\u001b[39m, in \u001b[36mPoolManager.urlopen\u001b[39m\u001b[34m(self, method, url, redirect, **kw)\u001b[39m\n\u001b[32m    457\u001b[39m     response = conn.urlopen(method, url, **kw)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     response = conn.urlopen(method, u.request_uri, **kw)\n\u001b[32m    461\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28mself\u001b[39m._make_request(\n\u001b[32m    788\u001b[39m     conn,\n\u001b[32m    789\u001b[39m     method,\n\u001b[32m    790\u001b[39m     url,\n\u001b[32m    791\u001b[39m     timeout=timeout_obj,\n\u001b[32m    792\u001b[39m     body=body,\n\u001b[32m    793\u001b[39m     headers=headers,\n\u001b[32m    794\u001b[39m     chunked=chunked,\n\u001b[32m    795\u001b[39m     retries=retries,\n\u001b[32m    796\u001b[39m     response_conn=response_conn,\n\u001b[32m    797\u001b[39m     preload_content=preload_content,\n\u001b[32m    798\u001b[39m     decode_content=decode_content,\n\u001b[32m    799\u001b[39m     **response_kw,\n\u001b[32m    800\u001b[39m )\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = conn.getresponse()\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28msuper\u001b[39m().getresponse()\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         response.begin()\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28mself\u001b[39m._read_status()\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/debut/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sock.recv_into(b)\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "errors_csv = \"data/results_errors.csv\"\n",
    "\n",
    "# Charger les liens déjà traités depuis results.csv et results_errors.csv\n",
    "processed_links = set()\n",
    "results_count = 0  # Nombre réel de lignes dans results.csv\n",
    "\n",
    "if os.path.exists(output_csv):\n",
    "    with open(output_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if row:\n",
    "                processed_links.add(row[0].strip())\n",
    "                results_count += 1\n",
    "\n",
    "# Charger aussi les liens déjà en erreur pour ne pas les retraiter en boucle\n",
    "errors_count = 0\n",
    "if os.path.exists(errors_csv):\n",
    "    with open(errors_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if row:\n",
    "                processed_links.add(row[0].strip())\n",
    "                errors_count += 1\n",
    "\n",
    "# Charger tous les liens à scraper (on enlève aussi les doublons tout en gardant l'ordre)\n",
    "if os.path.exists(input_csv):\n",
    "    with open(input_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "        all_links = [line.strip() for line in f if line.strip()]\n",
    "        all_links = list(dict.fromkeys(all_links))  # supprime les doublons\n",
    "else:\n",
    "    print(\"Fichier CSV d'entrée non trouvé.\")\n",
    "    all_links = []\n",
    "\n",
    "# Filtrer les liens non traités\n",
    "unprocessed_links = [link for link in all_links if link not in processed_links]\n",
    "\n",
    "print(f\"Trouvé {results_count} lignes dans results.csv\")\n",
    "print(f\"Trouvé {errors_count} erreurs dans results_errors.csv\")\n",
    "print(f\"Total: {len(processed_links)} liens uniques déjà traités (succès + erreurs).\")\n",
    "print(f\"Reprise avec {len(unprocessed_links)} liens restants à traiter.\")\n",
    "\n",
    "# Ouvrir results CSV en mode ajout\n",
    "with open(output_csv, \"a\", encoding=\"utf-8\", newline=\"\") as out_file, \\\n",
    "     open(errors_csv, \"a\", encoding=\"utf-8\", newline=\"\") as err_file:\n",
    "    \n",
    "    writer = csv.writer(out_file)\n",
    "    err_writer = csv.writer(err_file)\n",
    "\n",
    "    # Le compteur commence au nombre réel de lignes dans results.csv\n",
    "    processed_count = results_count\n",
    "\n",
    "    for link in unprocessed_links:\n",
    "        processed_count += 1\n",
    "\n",
    "        try:\n",
    "            print(f\"Traitement: {link}  ({processed_count}/{len(all_links)})\")\n",
    "            response = requests.get(link, headers=headers)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Erreur lors du chargement de la page: {response.status_code}\")\n",
    "                # On enregistre l'erreur une seule fois pour ne pas la retraiter\n",
    "                err_writer.writerow([link, response.status_code, \"http_error\"])\n",
    "                err_file.flush()\n",
    "                processed_links.add(link)\n",
    "                continue\n",
    "\n",
    "            content = response.text\n",
    "            data = scrape_annonce(link, content)\n",
    "\n",
    "            # Sérialiser les données scrapées en JSON pour éviter les problèmes de séparation de colonnes CSV\n",
    "            writer.writerow([link, json.dumps(data, ensure_ascii=False)])\n",
    "            out_file.flush()\n",
    "\n",
    "            # Marquer comme traité\n",
    "            processed_links.add(link)\n",
    "\n",
    "            sleep(2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du traitement {link}: {e}\")\n",
    "            # On log aussi les erreurs Python pour ne pas boucler dessus\n",
    "            err_writer.writerow([link, \"exception\", str(e)])\n",
    "            err_file.flush()\n",
    "            processed_links.add(link)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "debut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
